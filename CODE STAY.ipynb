{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/stay/stay.py\n",
    "\n",
    "from shlex import split\n",
    "from enum import Enum\n",
    "from collections.abc import Iterable\n",
    "from typing import Union, Dict, List\n",
    "from dataclasses import asdict, dataclass, is_dataclass\n",
    "\n",
    "T = Enum(\"Token\", \"start key comment long list\")\n",
    "D = Enum(\"Directive\", \"\")\n",
    "\n",
    "class ParsingError(Exception):\n",
    "    pass\n",
    "\n",
    "class StateMachine:\n",
    "    def __init__(self, *, states:dict, initial):       \n",
    "        self.states = {}\n",
    "        self.states.update(states)\n",
    "        self.state = initial\n",
    "        self.previous = initial\n",
    "    \n",
    "    def flux_to(self, to_state):\n",
    "        try:\n",
    "            if to_state in self.states[self.state]:                \n",
    "                self.previous = self.state\n",
    "                self.state = to_state\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except KeyError:\n",
    "            return False\n",
    "            \n",
    "    def __call__(self):\n",
    "        return self.state\n",
    "\n",
    "def load(file):\n",
    "    for x in loads(file.readlines()):\n",
    "        yield x\n",
    "\n",
    "        \n",
    "\n",
    "def do_long(n, l, parser, current_value):\n",
    "    if l.startswith(\":::\"):\n",
    "        current[current_key] = \"\\n\".join(current_value)\n",
    "        parser.flux_to(parser.previous)\n",
    "    else:\n",
    "        # to escape ::: in a long value, everything else already is escaped\n",
    "        if l.startswith(\"\\:::\"):\n",
    "            l = l[1:]\n",
    "        current_value.append(l.rstrip('\\n'))\n",
    "        \n",
    "def loads(text: List[str], spaces_per_indent=4):   \n",
    "    Parser = StateMachine(states={T.start:{T.long, T.start, T.key, T.comment, T.list},\n",
    "                                  T.key: {T.long, T.key, T.comment, T.list},\n",
    "                                  T.long: {T.long, T.start, T.key, T.comment, T.list},\n",
    "                                  T.list: {T.long, T.start, T.key, T.comment, T.list},\n",
    "                                  T.comment: {T.long, T.key, T.comment, T.start, T.list},\n",
    "                                 },\n",
    "                        initial=T.start)\n",
    "    \n",
    "    current = {}\n",
    "    stack = []\n",
    "    current_value = []\n",
    "    current_key = None\n",
    "    directives = set()\n",
    "\n",
    "    def level(l):\n",
    "        l = l.expandtabs(tabsize=spaces_per_indent)\n",
    "        return (len(l) - len(l.lstrip()))//spaces_per_indent\n",
    "    \n",
    "    for n, l in enumerate(text):                \n",
    "        # long values escape everything, even empty lines\n",
    "        if (l.isspace() or not l) and Parser() is not T.long:\n",
    "            continue\n",
    "            \n",
    "        # a short comment\n",
    "        if l.startswith(\"#\"):\n",
    "            # long values escape comments\n",
    "            if Parser() is T.long:\n",
    "                current_value.append(l)\n",
    "                continue\n",
    "                \n",
    "            if l.startswith(\"###\"):\n",
    "                # we may have a single \"### heading ###\"\n",
    "                if len(l.split()) > 2 and l.endswith(\"###\"):\n",
    "                    continue\n",
    "                elif Parser() is not T.comment:\n",
    "                    Parser.flux_to(T.comment)\n",
    "                else:\n",
    "                    Parser.flux_to(Parser.previous)\n",
    "            continue\n",
    "        \n",
    "        if Parser() is T.comment:\n",
    "            continue\n",
    "        \n",
    "        if Parser() is T.long:\n",
    "            if l.startswith(\":::\"):\n",
    "                current[current_key] = \"\\n\".join(current_value)\n",
    "                Parser.flux_to(Parser.previous)\n",
    "            else:\n",
    "                # to escape ::: in a long value, everything else already is escaped\n",
    "                if l.startswith(\"\\:::\"):\n",
    "                    l = l[1:]\n",
    "                current_value.append(l.rstrip('\\n'))\n",
    "            continue\n",
    "        \n",
    "        if Parser() is T.list:               \n",
    "            if l.startswith(\"]\"):\n",
    "                current[current_key] = current_value\n",
    "                Parser.flux_to(Parser.previous)\n",
    "                continue\n",
    "            \n",
    "            if l.startswith(\"\\]\"):\n",
    "                    l = l[1:]\n",
    "            \n",
    "            l = l.strip()\n",
    "\n",
    "            # like a matrix\n",
    "            if l.startswith(\"[\") and l.endswith(\"]\"):\n",
    "                l = l[1:-1]\n",
    "                l = split(l)\n",
    "\n",
    "            current_value.append(l)\n",
    "            continue\n",
    "             \n",
    "        # one might use more than 3 for aesthetics\n",
    "        if l.startswith(\"===\") or l.startswith(\"---\"):\n",
    "            Parser.flux_to(T.start)\n",
    "            yield current\n",
    "            current = {}\n",
    "            continue\n",
    "        \n",
    "        if l.startswith(\"%\"):\n",
    "            D = split(l[1:])\n",
    "            for x in D:\n",
    "                if x.startswith(\"+\"):\n",
    "                    try:\n",
    "                        d = getattr(D, x[1:])\n",
    "                        directives.add(d)\n",
    "                    except AttributeError:\n",
    "                        raise ParsingError(f\"No such directive: {x} (line {n})\")\n",
    "                elif d.startswith(\"-\"):\n",
    "                    try:\n",
    "                        d = getattr(D, x[1:])\n",
    "                        directives.discard(d)\n",
    "                    except AttributeError:\n",
    "                        raise ParsingError(f\"No such directive: {x} (line {n})\")\n",
    "            continue\n",
    "        \n",
    "        k, _, v = l.partition(\":\")\n",
    "        k, v = k.strip(), v.strip()\n",
    "        \n",
    "        if v == \"::\":\n",
    "            Parser.flux_to(T.long)\n",
    "            current_value = []\n",
    "            current_key = k.strip()\n",
    "            continue\n",
    "        \n",
    "        if v == \"::[\":\n",
    "            Parser.flux_to(T.list)\n",
    "            current_value = []\n",
    "            current_key = k.strip()\n",
    "            continue\n",
    "        \n",
    "        for x in range(abs(level(l) - len(stack))):\n",
    "                prev, prev_k = stack.pop()\n",
    "                prev[prev_k] = current\n",
    "                current = prev\n",
    "        \n",
    "        if v == \"\":\n",
    "            stack.append((current, k))\n",
    "            current = {}\n",
    "        else:\n",
    "            # this implements a list of values, just use \"[1 2 3 'foo bar' baz]\" to get [1,2,3, \"foo bar\", baz]\n",
    "            if v.startswith(\"[\") and v.endswith(\"]\"):\n",
    "                v = v[1:-1]\n",
    "                v = split(v)\n",
    "            \n",
    "            # simple values\n",
    "            current[k] = v\n",
    "    \n",
    "    for _ in range(len(stack)):\n",
    "        prev, prev_k = stack.pop()\n",
    "        prev[prev_k] = current\n",
    "        current = prev\n",
    "\n",
    "    yield current\n",
    "    \n",
    "def __process(D:dict, level=0, spaces_per_indent=4):\n",
    "    def do(k, v):\n",
    "        if not isinstance(v, Iterable) or (isinstance(v, str) and \"\\n\" not in v):\n",
    "            l = f\"{' ' * level * spaces_per_indent}{k}: {v}\\n\"\n",
    "\n",
    "        elif isinstance(v, str) and \"\\n\" in v:\n",
    "            l = f\"{' ' * level * spaces_per_indent}{k}:::\\n{v}\\n:::\\n\"\n",
    "\n",
    "        elif isinstance(v, Iterable) and not isinstance(v, dict):\n",
    "            l = f\"{' ' * level * spaces_per_indent}{k}: [{' '.join(str(x) for x in v)}]\\n\"\n",
    "\n",
    "        elif isinstance(v, dict):\n",
    "            l = f\"{' ' * level * spaces_per_indent}{k}:\\n\"\n",
    "            for k, v in v.items():\n",
    "                l += '\\n'.join(str(x) for x in __process(k, v, level=level+1))\n",
    "        else:\n",
    "            raise UserWarning\n",
    "        return l\n",
    "    \n",
    "    text = ''.join(do(k, v) for k, v in D.items())\n",
    "    return text\n",
    "\n",
    "def dumps(it:Union[Iterable, Dict, dataclass], spaces_per_indent=4):\n",
    "    \"\"\"Process an iterator of dictionaries as STAY documents, without comments.\"\"\"\n",
    "    it = [it] if isinstance(it, dict) else it\n",
    "    it = [asdict(it)] if is_dataclass(it) else it\n",
    "    \n",
    "    output = \"===\\n\".join(__process(asdict(D) if is_dataclass(D) else D) for D in it)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shlex import split\n",
    "from enum import Enum\n",
    "from collections.abc import Iterable\n",
    "from typing import Union, Dict, List\n",
    "from dataclasses import asdict, dataclass, is_dataclass\n",
    "\n",
    "T = Enum(\"Token\", \"start key comment long list\")\n",
    "D = Enum(\"Directive\", \"\")\n",
    "\n",
    "class ParsingError(Exception):\n",
    "    pass\n",
    "\n",
    "class StateMachine:\n",
    "    def __init__(self, *, states:dict, initial):       \n",
    "        self.states = {}\n",
    "        self.states.update(states)\n",
    "        self.state = initial\n",
    "        self.previous = initial\n",
    "    \n",
    "    def flux_to(self, to_state):\n",
    "        try:\n",
    "            if to_state in self.states[self.state]:                \n",
    "                self.previous = self.state\n",
    "                self.state = to_state\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except KeyError:\n",
    "            return False\n",
    "            \n",
    "    def __call__(self):\n",
    "        return self.state\n",
    "\n",
    "def load(file):\n",
    "    for x in loads(file.readlines()):\n",
    "        yield x\n",
    "\n",
    "def loads(text: List[str], spaces_per_indent=4):   \n",
    "    Parser = StateMachine(states={T.start:{T.long, T.start, T.key, T.comment, T.list},\n",
    "                                  T.key: {T.long, T.key, T.comment, T.list},\n",
    "                                  T.long: {T.long, T.start, T.key, T.comment, T.list},\n",
    "                                  T.list: {T.long, T.start, T.key, T.comment, T.list},\n",
    "                                  T.comment: {T.long, T.key, T.comment, T.start, T.list},\n",
    "                                 },\n",
    "                        initial=T.start)\n",
    "    \n",
    "    current = {}\n",
    "    stack = []\n",
    "    current_value = []\n",
    "    current_key = None\n",
    "    directives = set()\n",
    "\n",
    "    def level(l):\n",
    "        l = l.expandtabs(tabsize=spaces_per_indent)\n",
    "        return (len(l) - len(l.lstrip()))//spaces_per_indent\n",
    "    \n",
    "    for n, l in enumerate(text):                \n",
    "        # long values escape everything, even empty lines\n",
    "        if (l.isspace() or not l) and Parser() is not T.long:\n",
    "            continue\n",
    "            \n",
    "        # a short comment\n",
    "        if l.startswith(\"#\"):\n",
    "            # long values escape comments\n",
    "            if Parser() is T.long:\n",
    "                current_value.append(l)\n",
    "                continue\n",
    "                \n",
    "            if l.startswith(\"###\"):\n",
    "                # we may have a single \"### heading ###\"\n",
    "                if len(l.split()) > 2 and l.endswith(\"###\"):\n",
    "                    continue\n",
    "                elif Parser() is not T.comment:\n",
    "                    Parser.flux_to(T.comment)\n",
    "                else:\n",
    "                    Parser.flux_to(Parser.previous)\n",
    "            continue\n",
    "        \n",
    "        if Parser() is T.comment:\n",
    "            continue\n",
    "        \n",
    "        if Parser() is T.long:\n",
    "            if l.startswith(\":::\"):\n",
    "                current[current_key] = \"\\n\".join(current_value)\n",
    "                Parser.flux_to(Parser.previous)\n",
    "            else:\n",
    "                # to escape ::: in a long value, everything else already is escaped\n",
    "                if l.startswith(\"\\:::\"):\n",
    "                    l = l[1:]\n",
    "                current_value.append(l.rstrip('\\n'))\n",
    "            continue\n",
    "        \n",
    "        if Parser() is T.list:               \n",
    "            if l.startswith(\"]:::\"):\n",
    "                current[current_key] = current_value\n",
    "                Parser.flux_to(Parser.previous)\n",
    "                continue\n",
    "            \n",
    "            if l.startswith(\"\\]:::\"):\n",
    "                    l = l[1:]\n",
    "            \n",
    "            l = l.strip()\n",
    "\n",
    "            # like a matrix\n",
    "            if l.startswith(\"[\") and l.endswith(\"]\"):\n",
    "                l = l[1:-1]\n",
    "                l = split(l)\n",
    "\n",
    "            current_value.append(l)\n",
    "            continue\n",
    "             \n",
    "        # one might use more than 3 for aesthetics\n",
    "        if l.startswith(\"===\") or l.startswith(\"---\"):\n",
    "            Parser.flux_to(T.start)\n",
    "            yield current\n",
    "            current = {}\n",
    "            continue\n",
    "        \n",
    "        if l.startswith(\"%\"):\n",
    "            D = split(l[1:])\n",
    "            for x in D:\n",
    "                if x.startswith(\"+\"):\n",
    "                    try:\n",
    "                        d = getattr(D, x[1:])\n",
    "                        directives.add(d)\n",
    "                    except AttributeError:\n",
    "                        raise ParsingError(f\"No such directive: {x} (line {n})\")\n",
    "                elif d.startswith(\"-\"):\n",
    "                    try:\n",
    "                        d = getattr(D, x[1:])\n",
    "                        directives.discard(d)\n",
    "                    except AttributeError:\n",
    "                        raise ParsingError(f\"No such directive: {x} (line {n})\")\n",
    "            continue\n",
    "        \n",
    "        k, _, v = l.partition(\":\")\n",
    "        k, v = k.strip(), v.strip()\n",
    "        \n",
    "        if v == \"::\":\n",
    "            Parser.flux_to(T.long)\n",
    "            current_value = []\n",
    "            current_key = k.strip()\n",
    "            continue\n",
    "        \n",
    "        if v == \"::[\":\n",
    "            Parser.flux_to(T.list)\n",
    "            current_value = []\n",
    "            current_key = k.strip()\n",
    "            continue\n",
    "        \n",
    "        for x in range(abs(level(l) - len(stack))):\n",
    "                prev, prev_k = stack.pop()\n",
    "                prev[prev_k] = current\n",
    "                current = prev\n",
    "        \n",
    "        if v == \"\":\n",
    "            stack.append((current, k))\n",
    "            current = {}\n",
    "        else:\n",
    "            # this implements a list of values, just use \"[1 2 3 'foo bar' baz]\" to get [1,2,3, \"foo bar\", baz]\n",
    "            if v.startswith(\"[\") and v.endswith(\"]\"):\n",
    "                v = v[1:-1]\n",
    "                v = split(v)\n",
    "            \n",
    "            # simple values\n",
    "            current[k] = v\n",
    "    \n",
    "    for _ in range(len(stack)):\n",
    "        prev, prev_k = stack.pop()\n",
    "        prev[prev_k] = current\n",
    "        current = prev\n",
    "\n",
    "    yield current\n",
    "    \n",
    "def __process(D:dict, level=0, spaces_per_indent=4):\n",
    "    def do(k, v):\n",
    "        if not isinstance(v, Iterable) or (isinstance(v, str) and \"\\n\" not in v):\n",
    "            l = f\"{' ' * level * spaces_per_indent}{k}: {v}\\n\"\n",
    "\n",
    "        elif isinstance(v, str) and \"\\n\" in v:\n",
    "            l = f\"{' ' * level * spaces_per_indent}{k}:::\\n{v}\\n:::\\n\"\n",
    "\n",
    "        elif isinstance(v, Iterable) and not isinstance(v, dict):\n",
    "            l = f\"{' ' * level * spaces_per_indent}{k}: [{' '.join(str(x) for x in v)}]\\n\"\n",
    "\n",
    "        elif isinstance(v, dict):\n",
    "            l = f\"{' ' * level * spaces_per_indent}{k}:\\n\"\n",
    "            for k, v in v.items():\n",
    "                l += '\\n'.join(str(x) for x in __process(k, v, level=level+1))\n",
    "        else:\n",
    "            raise UserWarning\n",
    "        return l\n",
    "    \n",
    "    text = ''.join(do(k, v) for k, v in D.items())\n",
    "    return text\n",
    "\n",
    "def dumps(it:Union[Iterable, Dict, dataclass], spaces_per_indent=4):\n",
    "    \"\"\"Process an iterator of dictionaries as STAY documents, without comments.\"\"\"\n",
    "    it = [it] if isinstance(it, dict) else it\n",
    "    it = [asdict(it)] if is_dataclass(it) else it\n",
    "    \n",
    "    output = \"===\\n\".join(__process(asdict(D) if is_dataclass(D) else D) for D in it)\n",
    "    return output\n",
    "    \n",
    "it = [{1:2},{2:3}]\n",
    "dumps(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2\n",
    "\n",
    "def f(a):\n",
    "    print(a*2)\n",
    "    \n",
    "f(x if x < 2 else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plugins'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-871aa30d0de0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataclasses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dataclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplugins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDRV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Token\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"start key comment long list dicts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plugins'"
     ]
    }
   ],
   "source": [
    "from shlex import split\n",
    "from enum import Enum\n",
    "from collections.abc import Iterable\n",
    "from typing import Union, Dict, List, Sequence\n",
    "from dataclasses import asdict, dataclass, is_dataclass\n",
    "from plugins import DRV, directives\n",
    "\n",
    "T = Enum(\"Token\", \"start key comment long list dicts\")\n",
    "\n",
    "__version__ = 459\n",
    "\n",
    "class ParsingError(Exception):\n",
    "    pass\n",
    "\n",
    "@dataclass\n",
    "class State:\n",
    "    token = T.start\n",
    "    previous_token = None\n",
    "\n",
    "    current = {}\n",
    "    stack = []\n",
    "    current_value = []\n",
    "    current_key = None\n",
    "    directives = set()\n",
    "\n",
    "def do_list(n, line, st):\n",
    "    if line.startswith(\":::\"):\n",
    "        st.current[st.current_key] = \"\\n\".join(st.current_value)\n",
    "        st.token = st.previous_token\n",
    "    else:\n",
    "        # to escape ::: in a long value, everything else already is escaped\n",
    "        if line.startswith(r\"\\:::\"):\n",
    "            line = line[1:]\n",
    "        st.current_value.append(line.rstrip('\\n'))\n",
    "\n",
    "def do_long(n, line, st):\n",
    "    if line.startswith(\":::\"):\n",
    "        st.current[st.current_key] = \"\\n\".join(st.current_value)\n",
    "        st.token = st.previous_token\n",
    "\n",
    "def do_comment(n, line, st):\n",
    "    pass\n",
    "\n",
    "def do_list(n, line, st):\n",
    "    if line.startswith(\"]\"):\n",
    "        st.current[st.current_key] = st.current_value\n",
    "        st.token = st.previous_token\n",
    "        return\n",
    "    \n",
    "    if line.startswith(r\"\\]\"):\n",
    "            line = line[1:]\n",
    "    \n",
    "    line = line.strip()\n",
    "\n",
    "    # like a matrix, for instance\n",
    "    if line.startswith(\"[\") and line.endswith(\"]\"):\n",
    "        line = line[1:-1]\n",
    "        line = split(line)\n",
    "\n",
    "    st.current_value.append(line)\n",
    "\n",
    "def do_dicts(n, line, st):\n",
    "    if line.startswith(\"}\"):\n",
    "        st.current[st.current_key] = st.current_value\n",
    "        st.token = st.previous_token\n",
    "        return\n",
    "    \n",
    "    if line.startswith(r\"\\}\"):\n",
    "            line = line[1:]\n",
    "    line = line.strip()\n",
    "    st.current_value.append(line)\n",
    "\n",
    "\n",
    "cases = {T.comment: do_comment,\n",
    "        T.long: do_long,\n",
    "        T.list: do_list,\n",
    "        T.dicts: do_dicts,\n",
    "        }\n",
    "\n",
    "cases.update(directives)\n",
    "\n",
    "def load(file):\n",
    "    for x in loads(file.readlines()):\n",
    "        yield x\n",
    "\n",
    "def loads(lines, spaces_per_indent=4) -> Sequence[dict]:\n",
    "    lines = lines.splitlines() if isinstance(lines, str) else lines\n",
    "\n",
    "    st = State()\n",
    "\n",
    "    def level(line):\n",
    "        line = line.expandtabs(tabsize=spaces_per_indent)\n",
    "        return (len(line) - len(line.lstrip()))//spaces_per_indent\n",
    "    \n",
    "    for n, line in enumerate(lines):\n",
    "        # long values escape everything, even empty lines\n",
    "        if (line.isspace() or not line) and st.token is not T.long:\n",
    "            continue\n",
    "            \n",
    "        # a short comment\n",
    "        if line.startswith(\"#\"):\n",
    "            # long values escape comments\n",
    "            if st.token is T.long:\n",
    "                st.current_value.append(line)\n",
    "                continue\n",
    "                \n",
    "            if line.startswith(\"###\"):\n",
    "                # we may have a single \"### heading ###\"\n",
    "                if len(line.split()) > 2 and line.endswith(\"###\"):\n",
    "                    continue\n",
    "                elif st.token is not T.comment:\n",
    "                    st.previous_token = st.token\n",
    "                    st.token = T.comment\n",
    "                else:\n",
    "                    st.token = st.previous_token\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            print(3, st())\n",
    "            cases[st()](n, line, st)\n",
    "            continue\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # one might use more than 3 for aesthetics\n",
    "        if line.startswith(\"===\") or line.startswith(\"---\"):\n",
    "            if st.token is T.key:\n",
    "                raise ParsingError(f\"Key {st.current_key} but no value given.\")\n",
    "            else:\n",
    "                st.token = T.start\n",
    "            yield st.current\n",
    "            st.current = {}\n",
    "            continue\n",
    "        \n",
    "        if line.startswith(\"%\"):\n",
    "            D = split(line[1:])\n",
    "            for x in D:\n",
    "                if x.startswith(\"+\"):\n",
    "                    try:\n",
    "                        d = getattr(D, x[1:])\n",
    "                        directives.add(d)\n",
    "                    except AttributeError:\n",
    "                        raise ParsingError(f\"No such directive: {x} (line {n})\")\n",
    "                elif d.startswith(\"-\"):\n",
    "                    try:\n",
    "                        d = getattr(D, x[1:])\n",
    "                        directives.discard(d)\n",
    "                    except AttributeError:\n",
    "                        raise ParsingError(f\"No such directive: {x} (line {n})\")\n",
    "            continue\n",
    "        \n",
    "\n",
    "        k, _, v = line.partition(\":\")\n",
    "        k = k.strip()\n",
    "        # need to add a leading \" if spaces must not be ignored\n",
    "        if v.startswith('\"'):\n",
    "            v = v[1::]\n",
    "        else:\n",
    "            v = v.strip()\n",
    "        \n",
    "        if v == \"::\":\n",
    "            st.previous_token = st.token\n",
    "            st.token = T.long\n",
    "            st.current_value = []\n",
    "            st.current_key = k.strip()\n",
    "            continue\n",
    "        \n",
    "        if v == \"::[\":\n",
    "            st.previous_token = st.token\n",
    "            st.token = T.list\n",
    "            st.current_value = []\n",
    "            st.current_key = k.strip()\n",
    "            continue\n",
    "\n",
    "        if v == \"::{\":\n",
    "            st.previous_token = st.token\n",
    "            st.token = T.dicts\n",
    "            st.current_value = {}\n",
    "            st.current_key = k.strip()\n",
    "            continue\n",
    "        \n",
    "        for x in range(abs(level(line) - len(st.stack))):\n",
    "                prev, prev_k = st.stack.pop()\n",
    "                prev[prev_k] = st.current\n",
    "                st.current = prev\n",
    "        \n",
    "        if v == \"\":\n",
    "            st.stack.append((st.current, k))\n",
    "            st.current = {}\n",
    "        else:\n",
    "            # this implements a list of values, just use \"[1 2 3 'foo bar' baz]\" to get [1,2,3, \"foo bar\", baz]\n",
    "            if v.startswith(\"[\") and v.endswith(\"]\"):\n",
    "                v = v[1:-1]\n",
    "                v = split(v)\n",
    "            \n",
    "            # simple values\n",
    "            st.current[k] = v\n",
    "    \n",
    "    for _ in range(len(st.stack)):\n",
    "        prev, prev_k = st.stack.pop()\n",
    "        prev[prev_k] = st.current\n",
    "        st.current = prev\n",
    "\n",
    "    yield st.current\n",
    "    \n",
    "def __process(D:dict, level=0, spaces_per_indent=4):\n",
    "    def do(k, v):\n",
    "        if not isinstance(v, Iterable) or (isinstance(v, str) and \"\\n\" not in v):\n",
    "            line = f\"{' ' * level * spaces_per_indent}{k}: {v}\\n\"\n",
    "\n",
    "        elif isinstance(v, str) and \"\\n\" in v:\n",
    "            line = f\"{' ' * level * spaces_per_indent}{k}:::\\n{v}\\n:::\\n\"\n",
    "\n",
    "        elif isinstance(v, Iterable) and not isinstance(v, dict):\n",
    "            line = f\"{' ' * level * spaces_per_indent}{k}: [{' '.join(str(x) for x in v)}]\\n\"\n",
    "\n",
    "        elif isinstance(v, dict):\n",
    "            line = f\"{' ' * level * spaces_per_indent}{k}:\\n\"\n",
    "            for k, v in v.items():\n",
    "                line += '\\n'.join(str(x) for x in __process(k, v, level=level+1))\n",
    "        else:\n",
    "            raise UserWarning\n",
    "        return line\n",
    "    \n",
    "    text = ''.join(do(k, v) for k, v in D.items())\n",
    "    return text\n",
    "\n",
    "def dumps(it:Union[Iterable, Dict, dataclass], spaces_per_indent=4):\n",
    "    \"\"\"Process an iterator of dictionaries as STAY documents, without comments.\n",
    "    On second thought, it would be cool to auto-add comments, making the file self-documenting.\n",
    "    \"\"\"\n",
    "    it = [it] if isinstance(it, dict) else it\n",
    "    it = [asdict(it)] if is_dataclass(it) else it\n",
    "    \n",
    "    output = \"===\\n\".join(__process(asdict(D) if is_dataclass(D) else D) for D in it)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda n, l: None\n",
    "\n",
    "f(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo bar']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"foo bar\"\n",
    "\n",
    "def parse(s):\n",
    "    rest = s\n",
    "    x = y = -1\n",
    "    result = []\n",
    "    \n",
    "    def no_brackets():\n",
    "        nonlocal rest\n",
    "        _ = rest\n",
    "        rest = \"\"\n",
    "        return _\n",
    "\n",
    "    \n",
    "    def open_bracket():\n",
    "        pass\n",
    "    \n",
    "    def close_bracket():\n",
    "        pass\n",
    "    \n",
    "    def find_brackets():\n",
    "        nonlocal x, y\n",
    "        x, y = rest.find(\"[\"), rest.find(\"]\")\n",
    "        if x == y == -1:\n",
    "            no_brackets()\n",
    "        x = x if x != -1 else inf\n",
    "        y = y if y != -1 else inf\n",
    "        \n",
    "        if x < y:\n",
    "            open_bracket()\n",
    "        if x > y:\n",
    "            close_bracket()\n",
    "    \n",
    "    while len(rest) > 0:\n",
    "        result.append(find_brackets())\n",
    "    return result\n",
    "        \n",
    "parse(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loads' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-28b584f4a773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \"\"\"\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loads' is not defined"
     ]
    }
   ],
   "source": [
    "t = \"\"\"\n",
    "\n",
    "x:::[\n",
    "[1 2 3]\n",
    "[2 3 4]\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "list(loads(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listoflists:::[\n",
    "1 2 3\n",
    "[foo bar]\n",
    "foo bar\n",
    "[4 5 6]\n",
    "foo bar [7 8 9 [ß]] adf\n",
    "]\n",
    "[\"foo\", \"bar\"]\n",
    "\"foo bar\"\n",
    "\n",
    "[[\"1 2 3\",[\"4\",\"5\",\"6\"], \"foo bar\", [\"7\",\"8\",\"9\", [\"ß\"]] \"adf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile plugin_test.py\n",
    "\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stay_plugin_test.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x*3\n",
    "\n",
    "def g(x):\n",
    "    return x*5\n",
    "\n",
    "def h(x):\n",
    "    return x*7\n",
    "\n",
    "cases = {frozenset()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7a6439d826ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-7a6439d826ed>\u001b[0m in \u001b[0;36mg\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x > 2 and x <7:\n",
    "        return x\n",
    "    \n",
    "def g(x):\n",
    "    cases = {frozenset(list(range(2,7))): lambda: x}\n",
    "    cases[x]()\n",
    "    \n",
    "g(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% +key_CAP\n",
      "hallo: Sarah\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DRV.key_CAP: 1>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "DRV = Enum(\"DRV\", \"key_CAP\")\n",
    "\n",
    "text = \"% +key_CAP\\nhallo: Sarah\"\n",
    "for l in text.splitlines():\n",
    "    print(l)\n",
    "\n",
    "DRV[\"key_CAP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['%', 'key_cap', '']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"%:key_cap:\".split(\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enum 'preline directive'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRE_DRV = Enum(\"preline directive\", \"CAP\")\n",
    "\n",
    "PRE_DRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CAP', 'ASDF'), ('MUL', 'ASDFASDFASDF')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def CAP():\n",
    "    def do(line):\n",
    "        return line.upper() \n",
    "    return do\n",
    "\n",
    "def mul(num):\n",
    "    def do(line):\n",
    "        return line * num\n",
    "    return do\n",
    "\n",
    "PRE_DRV = Enum(\"preline directive\", \"CAP\")\n",
    "\n",
    "directives = {\"CAP\": CAP(), \"MUL\": mul(3)}\n",
    "s = \"asdf\"\n",
    "result = []\n",
    "current = s\n",
    "for d,f in directives.items():\n",
    "    current = f(current)\n",
    "    result.append((d, current))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADSF'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"adsf\".upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '+', 'list_to_set', ' foo=234']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"%True%list_to_set% foo=234\".split(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = \"list_to_set in DRV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"%list_to_set:\".partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.partition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"\n",
    "nc: http://release.niem.gov/niem/niem-core/4.0/#\n",
    "j: http://release.niem.gov/niem/domains/jxdm/6.0/#\n",
    "age: nc:PersonAgeMeasure\n",
    "value: nc:MeasureIntegerValue\n",
    "units: nc:TimeUnitCode\n",
    "hairColor: j:PersonHairColorCode\n",
    "name: nc:PersonName\n",
    "given: nc:PersonGivenName\n",
    "surname: PersonSurName\n",
    "suffix: PersonNameSuffixText\n",
    "nickname: PersonPreferredName\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='http', netloc='release.niem.gov', path='/niem/niem-core/4.0/', params='', query='', fragment='')\n",
      "ParseResult(scheme='http', netloc='release.niem.gov', path='/niem/domains/jxdm/6.0/', params='', query='', fragment='')\n",
      "ParseResult(scheme='nc', netloc='', path='PersonAgeMeasure', params='', query='', fragment='')\n",
      "nc PersonAgeMeasure\n",
      "ParseResult(scheme='nc', netloc='', path='MeasureIntegerValue', params='', query='', fragment='')\n",
      "nc MeasureIntegerValue\n",
      "ParseResult(scheme='nc', netloc='', path='TimeUnitCode', params='', query='', fragment='')\n",
      "nc TimeUnitCode\n",
      "ParseResult(scheme='j', netloc='', path='PersonHairColorCode', params='', query='', fragment='')\n",
      "j PersonHairColorCode\n",
      "ParseResult(scheme='nc', netloc='', path='PersonName', params='', query='', fragment='')\n",
      "nc PersonName\n",
      "ParseResult(scheme='nc', netloc='', path='PersonGivenName', params='', query='', fragment='')\n",
      "nc PersonGivenName\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "d = {}\n",
    "\n",
    "for l in s.splitlines():\n",
    "    def expand(v):\n",
    "        head, _, tail = v.partition(\":\")\n",
    "        if _:\n",
    "            url = urlparse(v)\n",
    "            if not url.scheme or not url.netloc:\n",
    "                try:\n",
    "                    v = d[head] + tail\n",
    "                except:\n",
    "                    pass\n",
    "        return v\n",
    "        \n",
    "    k, p, v = (p.strip() for p in l.partition(\":\"))\n",
    "    v = expand(v)\n",
    "    if p:\n",
    "        d[k]= v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nc': 'http://release.niem.gov/niem/niem-core/4.0/#',\n",
       " 'j': 'http://release.niem.gov/niem/domains/jxdm/6.0/#',\n",
       " 'age': 'http://release.niem.gov/niem/niem-core/4.0/#PersonAgeMeasure',\n",
       " 'value': 'http://release.niem.gov/niem/niem-core/4.0/#MeasureIntegerValue',\n",
       " 'units': 'http://release.niem.gov/niem/niem-core/4.0/#TimeUnitCode',\n",
       " 'hairColor': 'http://release.niem.gov/niem/domains/jxdm/6.0/#PersonHairColorCode',\n",
       " 'name': 'http://release.niem.gov/niem/niem-core/4.0/#PersonName',\n",
       " 'given': 'http://release.niem.gov/niem/niem-core/4.0/#PersonGivenName',\n",
       " 'surname': 'PersonSurName',\n",
       " 'suffix': 'PersonNameSuffixText',\n",
       " 'nickname': 'PersonPreferredName'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
