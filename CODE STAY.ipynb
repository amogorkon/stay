{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = \"###\\n\"\n",
    "\n",
    "len(l.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = \"   l\\t\\n\"\n",
    "l.isspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 'b'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stay import loads\n",
    "\n",
    "text = \"\"\"\n",
    "###\n",
    "asdf\n",
    "###\n",
    "a: b\n",
    "\"\"\"\n",
    "\n",
    "list(loads(text.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2, 3}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = set()\n",
    "x = [1,2]\n",
    "y = [1,3]\n",
    "\n",
    "s.update(x)\n",
    "s.update(y)\n",
    "s.discard(1)\n",
    "s.discard(1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "start",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-1da7b9aec6c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"start\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/enum.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_member_map_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: start"
     ]
    }
   ],
   "source": [
    "from shlex import split\n",
    "from enum import Enum\n",
    "from collections.abc import Iterable\n",
    "from typing import Union, Dict, List\n",
    "from dataclasses import asdict, dataclass, is_dataclass\n",
    "\n",
    "T = Enum(\"Token\", \"start key comment long list\")\n",
    "D = Enum(\"Directive\", \"\")\n",
    "\n",
    "x = \"start\"\n",
    "hasattr(T, x)\n",
    "getattr(D, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/stay.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/stay.py\n",
    "\n",
    "from shlex import split\n",
    "from enum import Enum\n",
    "from collections.abc import Iterable\n",
    "from typing import Union, Dict, List\n",
    "from dataclasses import asdict, dataclass, is_dataclass\n",
    "\n",
    "T = Enum(\"Token\", \"start key comment long list\")\n",
    "D = Enum(\"Directive\", \"\")\n",
    "\n",
    "class ParsingError(Exception):\n",
    "    pass\n",
    "\n",
    "class StateMachine:\n",
    "    def __init__(self, *, states:dict, initial):       \n",
    "        self.states = {}\n",
    "        self.states.update(states)\n",
    "        self.state = initial\n",
    "        self.previous = initial\n",
    "    \n",
    "    def flux_to(self, to_state):\n",
    "        try:\n",
    "            if to_state in self.states[self.state]:                \n",
    "                self.previous = self.state\n",
    "                self.state = to_state\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except KeyError:\n",
    "            return False\n",
    "            \n",
    "    def __call__(self):\n",
    "        return self.state\n",
    "\n",
    "def load(file):\n",
    "    for x in loads(file.readlines()):\n",
    "        yield x\n",
    "\n",
    "def loads(text: List[str], spaces_per_indent=4):   \n",
    "    Parser = StateMachine(states={T.start:{T.long, T.start, T.key, T.comment, T.list},\n",
    "                                  T.key: {T.long, T.key, T.comment, T.list},\n",
    "                                  T.long: {T.long, T.start, T.key, T.comment, T.list},\n",
    "                                  T.list: {T.long, T.start, T.key, T.comment, T.list},\n",
    "                                  T.comment: {T.long, T.key, T.comment, T.start, T.list},\n",
    "                                 },\n",
    "                        initial=T.start)\n",
    "    \n",
    "    current = {}\n",
    "    stack = []\n",
    "    current_value = []\n",
    "    current_key = None\n",
    "    directives = set()\n",
    "\n",
    "    def level(l):\n",
    "        l = l.expandtabs(tabsize=spaces_per_indent)\n",
    "        return (len(l) - len(l.lstrip()))//spaces_per_indent\n",
    "    \n",
    "    for n, l in enumerate(text):                \n",
    "        # long values escape everything, even empty lines\n",
    "        if (l.isspace() or not l) and Parser() is not T.long:\n",
    "            continue\n",
    "            \n",
    "        # a short comment\n",
    "        if l.startswith(\"#\"):\n",
    "            # long values escape comments\n",
    "            if Parser() is T.long:\n",
    "                current_value.append(l)\n",
    "                continue\n",
    "                \n",
    "            if l.startswith(\"###\"):\n",
    "                # we may have a single \"### heading ###\"\n",
    "                if len(l.split()) > 2 and l.endswith(\"###\"):\n",
    "                    continue\n",
    "                elif Parser() is not T.comment:\n",
    "                    Parser.flux_to(T.comment)\n",
    "                else:\n",
    "                    Parser.flux_to(Parser.previous)\n",
    "            continue\n",
    "        \n",
    "        if Parser() is T.comment:\n",
    "            continue\n",
    "        \n",
    "        if Parser() is T.long:\n",
    "            if l.startswith(\":::\"):\n",
    "                current[current_key] = \"\\n\".join(current_value)\n",
    "                Parser.flux_to(Parser.previous)\n",
    "            else:\n",
    "                # to escape ::: in a long value, everything else already is escaped\n",
    "                if l.startswith(\"\\:::\"):\n",
    "                    l = l[1:]\n",
    "                current_value.append(l.rstrip('\\n'))\n",
    "            continue\n",
    "        \n",
    "        if Parser() is T.list:               \n",
    "            if l.startswith(\"]:::\"):\n",
    "                current[current_key] = current_value\n",
    "                Parser.flux_to(Parser.previous)\n",
    "                continue\n",
    "            \n",
    "            if l.startswith(\"\\]:::\"):\n",
    "                    l = l[1:]\n",
    "\n",
    "            # like a matrix\n",
    "            if l.startswith(\"[\") and l.endswith(\"]\"):\n",
    "                l = l[1:-1]\n",
    "                l = split(l)\n",
    "\n",
    "            current_value.append(l)\n",
    "            continue\n",
    "             \n",
    "        # one might use more than 3 for aesthetics\n",
    "        if l.startswith(\"===\") or l.startswith(\"---\"):\n",
    "            Parser.flux_to(T.start)\n",
    "            yield current\n",
    "            current = {}\n",
    "            continue\n",
    "        \n",
    "        if l.startswith(\"%\"):\n",
    "            D = split(l[1:])\n",
    "            for x in D:\n",
    "                if x.startswith(\"+\"):\n",
    "                    try:\n",
    "                        d = getattr(D, x[1:])\n",
    "                        directives.add(d)\n",
    "                    except AttributeError:\n",
    "                        raise ParsingError(f\"No such directive: {x} (line {n})\")\n",
    "                elif d.startswith(\"-\"):\n",
    "                    try:\n",
    "                        d = getattr(D, x[1:])\n",
    "                        directives.discard(d)\n",
    "                    except AttributeError:\n",
    "                        raise ParsingError(f\"No such directive: {x} (line {n})\")\n",
    "            continue\n",
    "        \n",
    "        k, _, v = l.partition(\":\")\n",
    "        k, v = k.strip(), v.strip()\n",
    "        \n",
    "        if v == \"::\":\n",
    "            Parser.flux_to(T.long)\n",
    "            current_value = []\n",
    "            current_key = k.strip()\n",
    "            continue\n",
    "        \n",
    "        if v == \"::[\":\n",
    "            Parser.flux_to(T.list)\n",
    "            current_value = []\n",
    "            current_key = k.strip()\n",
    "            continue\n",
    "        \n",
    "        for x in range(abs(level(l) - len(stack))):\n",
    "                prev, prev_k = stack.pop()\n",
    "                prev[prev_k] = current\n",
    "                current = prev\n",
    "        \n",
    "        if v == \"\":\n",
    "            stack.append((current, k))\n",
    "            current = {}\n",
    "        else:\n",
    "            # this implements a list of values, just use \"[1 2 3 'foo bar' baz]\" to get [1,2,3, \"foo bar\", baz]\n",
    "            if v.startswith(\"[\") and v.endswith(\"]\"):\n",
    "                v = v[1:-1]\n",
    "                v = split(v)\n",
    "            \n",
    "            # simple values\n",
    "            current[k] = v\n",
    "    \n",
    "    for _ in range(len(stack)):\n",
    "        prev, prev_k = stack.pop()\n",
    "        prev[prev_k] = current\n",
    "        current = prev\n",
    "\n",
    "    yield current\n",
    "    \n",
    "def __process(k, v, level=0, spaces_per_indent=4):\n",
    "    if not isinstance(v, Iterable) or (isinstance(v, str) and \"\\n\" not in v):\n",
    "        l = f\"{' ' * level * spaces_per_indent}{k}: {v}\\n\"\n",
    "\n",
    "    elif isinstance(v, str) and \"\\n\" in v:\n",
    "        l = f\"{' ' * level * spaces_per_indent}{k}:::\\n{v}\\n:::\\n\"\n",
    "\n",
    "    elif isinstance(v, Iterable) and not isinstance(v, dict):\n",
    "        l = f\"{' ' * level * spaces_per_indent}{k}: [{' '.join(str(x) for x in v)}]\\n\"\n",
    "\n",
    "    elif isinstance(v, dict):\n",
    "        l = f\"{' ' * level * spaces_per_indent}{k}:\\n\"\n",
    "        for k, v in v.items():\n",
    "            l += '\\n'.join(str(x) for x in __process(k, v, level=level+1))\n",
    "    else:\n",
    "        raise UserWarning\n",
    "\n",
    "    yield l\n",
    "\n",
    "def dumps(it:Union[Iterable, Dict, dataclass], spaces_per_indent=4):\n",
    "    \"\"\"Process an iterator of dictionaries as SAY documents, without comments.\"\"\"\n",
    "    it = [it] if isinstance(it, dict) else it\n",
    "    it = [asdict(it)] if is_dataclass(it) else it\n",
    "    \n",
    "    assert isinstance(it, Iterable)\n",
    "    text = \"\"\n",
    "    \n",
    "    for D in it:\n",
    "        if is_dataclass(D):\n",
    "            D = asdict(D)\n",
    "        assert isinstance(D, dict)\n",
    "        for k, v in D.items():\n",
    "            text += '===\\n'.join(__process(k, v))\n",
    "        \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting META.stay\n"
     ]
    }
   ],
   "source": [
    "%%writefile META.stay\n",
    "\n",
    "NAME: stay\n",
    "description: Simple, even Trivial Alternative to Yaml\n",
    "license: MIT\n",
    "url: github.bla\n",
    "version: 0.1.10\n",
    "author: Anselm Kiefner\n",
    "author_email: stay-pypi@anselm.kiefner.de\n",
    "\n",
    "\n",
    "KEYWORDS: [json yaml toml config simple alternative]\n",
    "CLASSIFIERS:::[\n",
    "    \n",
    "Development Status :: 4 - Beta\n",
    "Intended Audience :: Developers\n",
    "Natural Language :: English\n",
    "License :: OSI Approved :: MIT License\n",
    "Operating System :: OS Independent\n",
    "Programming Language :: Python :: 3 :: Only\n",
    "Programming Language :: Python :: Implementation :: CPython\n",
    "Topic :: Text Processing :: Markup\n",
    "\n",
    "]:::\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.py\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "from stay import load\n",
    "\n",
    "with open(\"META.stay\") as f:\n",
    "    for meta in load(f):\n",
    "        pass\n",
    "\n",
    "with open(\"README.rst\") as f:\n",
    "    LONG_DESCRIPTION = f.read()\n",
    "    \n",
    "def setup(*args, **kwargs):\n",
    "    print(args)\n",
    "    print(kwargs)\n",
    "\n",
    "setup(\n",
    "    PACKAGES=find_packages(where=\"src\"),\n",
    "    long_description=LONG_DESCRIPTION,\n",
    "    package_dir={\"\": \"src\"},\n",
    "    zip_safe=False,\n",
    "    INSTALL_REQUIRES: [],\n",
    "    **meta\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
